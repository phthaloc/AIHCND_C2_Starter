{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "Numpy version: 1.19.1\n",
      "Pandas version: 1.1.3\n",
      "Tensorflow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# hint: notebook is executed in jupyter lab dark mode\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# see https://matplotlib.org/gallery/style_sheets/style_sheets_reference.html for styles\n",
    "plt.style.use('dark_background')\n",
    "# global color settings (use white/grey for jupyterlab dark mode\n",
    "# and black/grey for jupyterlab light mode)\n",
    "COLOR = 'grey'\n",
    "plt.rcParams['text.color'] = COLOR\n",
    "plt.rcParams['axes.labelcolor'] = COLOR\n",
    "plt.rcParams['xtick.color'] = COLOR\n",
    "plt.rcParams['ytick.color'] = COLOR\n",
    "# plt.rcParams['grid.color'] = COLOR\n",
    "# plt.rcParams['figure.edgecolor'] = 'red'\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f'Python version: {sys.version}')\n",
    "print(f'Numpy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "\n",
    "# the following code snippet is necessary for tensorflow training to work (tf2.2, cuda10.2 or 10.1)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## location to save the models\n",
    "PATH_MODEL = 'models/model_vgg16_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConstructorError",
     "evalue": "could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:numpy.core.multiarray.scalar'\n  in \"models/model_vgg16_1/config_parameters.yaml\", line 11, column 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConstructorError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0ff508e94e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# The FullLoader parameter handles the conversion from YAML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# scalar values to Python the dictionary format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFullLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdict_cfg_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_cfg_rand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_cfg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_cfg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_single_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mget_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_single_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mconstruct_document\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_generators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_generators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdummy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstructed_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mconstruct_yaml_map\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mconstruct_mapping\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMappingNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_yaml_null\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mconstruct_mapping\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 raise ConstructorError(\"while constructing a mapping\", node.start_mark,\n\u001b[1;32m    142\u001b[0m                         \"found unhashable key\", key_node.start_mark)\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mconstruct_object\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mconstructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag_suffix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py38ml/lib/python3.8/site-packages/yaml/constructor.py\u001b[0m in \u001b[0;36mconstruct_undefined\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_undefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         raise ConstructorError(None, None,\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0;34m\"could not determine a constructor for the tag %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 node.start_mark)\n",
      "\u001b[0;31mConstructorError\u001b[0m: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object/apply:numpy.core.multiarray.scalar'\n  in \"models/model_vgg16_1/config_parameters.yaml\", line 11, column 11"
     ]
    }
   ],
   "source": [
    "with open(f'{PATH_MODEL}config_parameters.yaml') as file:\n",
    "    # The FullLoader parameter handles the conversion from YAML\n",
    "    # scalar values to Python the dictionary format\n",
    "    lst = yaml.load(file, Loader=yaml.FullLoader)\n",
    "dict_cfg_paths, dict_cfg_rand, dict_cfg_model, dict_cfg_data = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dicom(dcm):\n",
    "    \"\"\"\n",
    "    Checks dicom metadata header for important fields of the\n",
    "    implemented model and raises NotImplementedError if the\n",
    "    dicom file has unmaching parameters.\n",
    "    :param dcm: dicom file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    ## check proper image acquisition type:\n",
    "    if not dcm.Modality.lower() in ['dx']:\n",
    "        txt = (f\"{dcm.Modality} is not a valid image acquisition type. \" + \n",
    "               \"The trained model only works on 'dx' images.\")\n",
    "        raise NotImplementedError(txt)\n",
    "\n",
    "    ## check proper image body part:\n",
    "    if not dcm.BodyPartExamined.lower() in ['chest']:\n",
    "        txt = (f\"{dcm.BodyPartExamined} is not a valid body part. \" +\n",
    "               \"The trained model only works on chest x-ray images.\")\n",
    "        raise NotImplementedError(txt)\n",
    "\n",
    "    ## check proper patient position/ image acquisition orientation\n",
    "    if not dcm.PatientPosition.lower() in ['pa', 'ap']:\n",
    "        txt = (f\"{dcm.PatientPosition} is not a valid image orientation. \" +\n",
    "               \"The trained model only works on viewing positions 'ap' and 'pa'.\")\n",
    "        raise NotImplementedError(txt)\n",
    "\n",
    "        \n",
    "def import_dicom(filename, perform_check=True, print_metadata=False):\n",
    "    \"\"\"\n",
    "    This function reads in a .dcm file, checks for relevant parameters (optional) and returns the image data\n",
    "    :param filename: path to dicom file\n",
    "    :param perform_check: boolean, set true to check the important fields (metadata) of the implemented model\n",
    "    :param print_metadata: boolean, if true print all relevant dicom metadata\n",
    "    :returns: returns a numpy array of just the imaging data\n",
    "    \"\"\"\n",
    "    print(f'Load file {filename} ...')\n",
    "    ## import dicom image\n",
    "    dcm = pydicom.dcmread(filename)\n",
    "    \n",
    "    if perform_check:\n",
    "        check_dicom(dcm)\n",
    "    \n",
    "    if print_metadata: \n",
    "        print(f'PID: {dcm.PatientID}')\n",
    "        print(f'Patient sex: {dcm.PatientSex}')\n",
    "        print(f'Patient age: {int(dcm.PatientAge)}')\n",
    "        print(f'Patient position: {dcm.PatientPosition}')\n",
    "        print(f'Examined body part: {dcm.BodyPartExamined}')\n",
    "        print(f'Modality: {dcm.Modality}')\n",
    "        print(f'Findings: {dcm.StudyDescription}')\n",
    "        print(f'image dimensions: {dcm.Rows} x {dcm.Columns}')\n",
    "        print()\n",
    "    \n",
    "    # get image data (np array)\n",
    "    img = dcm.pixel_array\n",
    "    return img\n",
    "\n",
    "\n",
    "def dicom_label(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract label of dicom file\n",
    "    :param filename: path to dicom file\n",
    "    :return: dicom label (string)\n",
    "    \"\"\"\n",
    "    dcm = pydicom.dcmread(filename)\n",
    "    return dcm.StudyDescription.lower().replace(' ', '_')\n",
    "\n",
    "\n",
    "def dicom_pneumonia_label(filename: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract pneumonia label\n",
    "    :param filename: path to dicom file\n",
    "    :return: pneumonia label ({0, 1})\n",
    "    \"\"\"\n",
    "    if dicom_label(filename=filename) in ('pneumonia'):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "# def preprocess_image_old(img: np.array, img_mean: float, img_std: float,\n",
    "#                      img_size: tuple, scale_type: str):\n",
    "#     \"\"\"\n",
    "#     This function takes the numpy array output by import_dicom and \n",
    "#     runs the appropriate pre-processing needed for our model input\n",
    "\n",
    "#     \"\"\"\n",
    "#     img_pil = PIL.Image.fromarray(img)\n",
    "#     ## resize image:\n",
    "#     ## use nearest for intrpolation. this is used in keras as of June 2020\n",
    "#     ## nearest: Pick one nearest pixel from the input image. Ignore all other input pixels.\n",
    "#     proc_img = img_pil.resize(size=img_size, resample=PIL.Image.NEAREST)\n",
    "#     if not scale_type:\n",
    "#         proc_img = np.array(proc_img)\n",
    "#     elif scale_type.lower()=='standardization':\n",
    "#         proc_img = (np.array(proc_img) - img_mean) / img_std\n",
    "#     elif scale_type.lower()=='normalization':\n",
    "#         proc_img = np.array(proc_img) / 255.0\n",
    "#     else:\n",
    "#         raise NotImplementedError(\"Scaling type must be either 'standardization', 'normalization' or None\")\n",
    "#     ## reshape image from grayscale to rgb and introduce batch dimension:\n",
    "#     proc_img = tf.image.grayscale_to_rgb(tf.reshape(proc_img, (1, *tuple(img_size), 1)))\n",
    "#     return proc_img.numpy()\n",
    "\n",
    "\n",
    "def preprocess_image(img: np.array, img_size: tuple, model_architecture: str='vgg16'):\n",
    "    \"\"\"\n",
    "    This function takes the numpy array output by import_dicom and \n",
    "    runs the appropriate pre-processing needed for our model input\n",
    "    :param img:\n",
    "    :param img_size:\n",
    "    :param model_architecture: (optional) architecture of pretrained base model\n",
    "    \"\"\"\n",
    "    img_pil = PIL.Image.fromarray(img)\n",
    "    ## resize image:\n",
    "    ## use nearest for intrpolation. this is used in keras as of June 2020\n",
    "    ## nearest: Pick one nearest pixel from the input image. Ignore all other input pixels.\n",
    "    proc_img = np.array(img_pil.resize(size=img_size, resample=PIL.Image.NEAREST))\n",
    "    ## reshape image from grayscale to rgb and introduce batch dimension:\n",
    "    proc_img = tf.image.grayscale_to_rgb(tf.reshape(proc_img, (1, *tuple(img_size), 1)))\n",
    "    if model_architecture=='vgg16':\n",
    "        # The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling:\n",
    "        return keras.applications.vgg16.preprocess_input(x=np.array(proc_img))\n",
    "    elif model_architecture=='resnet50':\n",
    "        # The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling:\n",
    "        return keras.applications.resnet.preprocess_input(x=np.array(proc_img))\n",
    "    elif model_architecture=='densenet121':\n",
    "        # The input pixels values are scaled between 0 and 1 and each channel is normalized with respect to the ImageNet dataset:\n",
    "        return keras.applications.densenet.preprocess_input(x=np.array(proc_img))\n",
    "    else:\n",
    "        raise NotImplementedError('Model has not been implemented yet. Implemented pretrained models are vgg16, resnet50, densenet121')\n",
    "\n",
    "# def preprocess_image(img, plot=False):\n",
    "#     # Resize\n",
    "#     IMG_SIZE = (224, 224)\n",
    "#     resized_img = np.expand_dims(img, axis=2)\n",
    "#     resized_img = tf.image.grayscale_to_rgb(tf.convert_to_tensor(resized_img)).numpy()\n",
    "#     resized_img = np.array(Image.fromarray(resized_img).resize((IMG_SIZE))) # Use PIL to avoid scaling to 0-1 range\n",
    "    \n",
    "#     # Apply ResNet Preprocessing\n",
    "#     # NOTE: ResNet image preprocessing in TF.Keras uses \"caffe\" pre-processing style, which is recentered but not normalized\n",
    "#     proc_img = np.expand_dims(resized_img, axis=0)\n",
    "#     proc_img = preprocess_input_ResNet(proc_img)\n",
    "#     return proc_img\n",
    "\n",
    "\n",
    "\n",
    "def load_model(path_model, path_weights):\n",
    "    \"\"\"\n",
    "    This function loads in the trained model with weights and compiles it \n",
    "    \"\"\"\n",
    "    # model does not have to be compiled because we do not want to train it here\n",
    "#     model = keras.models.load_model(path_model, compile=False)\n",
    "#     model.load_weights(path_weights)\n",
    "    with open(path_model, 'r') as json_file:\n",
    "        model_json = json_file.read()\n",
    "    model = keras.models.model_from_json(model_json)\n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh: float): \n",
    "    \"\"\"\n",
    "    Classify a (preprocessed) X-ray image based on the model threshold parameter\n",
    "    to predict whether or not the image shows the presence of pneumonia\n",
    "\n",
    "    \"\"\"\n",
    "    pred = model.predict(img, verbose=0)\n",
    "    if pred[0][0] >= thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "# model_path = f'{PATH_MODEL}pneumonia_model'\n",
    "model_path = f'{PATH_MODEL}pneumonia_model.json'\n",
    "weight_path = f'{PATH_MODEL}weights/weights.hdf5'\n",
    "\n",
    "IMG_SIZE = dict_cfg_model['IMG_SIZE']\n",
    "\n",
    "my_model = load_model(path_model=model_path, path_weights=weight_path)\n",
    "thresh = dict_cfg_model['thresh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in lst_test_dicoms:\n",
    "    try:\n",
    "        img = import_dicom(i, perform_check=True, print_metadata=False)\n",
    "    except NotImplementedError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "#     img_proc = preprocess_image(img=img, img_mean=img_mean, img_std=img_std,\n",
    "#                                 img_size=IMG_SIZE, scale_type=dict_cfg_data['SCALE_TYPE'])\n",
    "    img_proc = preprocess_image(\n",
    "        img=img, img_size=IMG_SIZE,\n",
    "        model_architecture=dict_cfg_model['MODEL_BASE_ARCHITECTURE']\n",
    "    )\n",
    "    pred = predict_image(model=my_model, img=img_proc, thresh=thresh)\n",
    "    label_dicom = dicom_label(filename=i)\n",
    "    label_pneumonia = dicom_pneumonia_label(filename=i)\n",
    "    print(f'model pneumonia prediction: {pred}, pneumonia label: ' +\n",
    "          f'{label_pneumonia} (label dicom file: {label_dicom})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = import_dicom(filename='test1.dcm', perform_check=False, print_metadata=True)\n",
    "plt.imshow(img_test, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,12));\n",
    "plt.subplot(2,2,1);\n",
    "plt.imshow(img_test);\n",
    "plt.title(\"Input Image\");\n",
    "\n",
    "plt.subplot(2,2,2);\n",
    "plt.hist(img_test.ravel(), bins=256);\n",
    "plt.title(\"Intensities Before Preprocessing\");\n",
    "\n",
    "img_proc = preprocess_image(\n",
    "    img=img_test, img_size=IMG_SIZE,\n",
    "    model_architecture=dict_cfg_model['MODEL_BASE_ARCHITECTURE']\n",
    ")\n",
    "\n",
    "plt.subplot(2,2,3);\n",
    "plt.imshow(img_proc[0,:,:,0]);\n",
    "plt.title('Preprocessed Image for Inference');\n",
    "\n",
    "plt.subplot(2,2,4);\n",
    "plt.hist(img_proc[0].ravel(), bins=256);\n",
    "plt.title(\"Intensities After Preprocessing\");\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38ml_tf",
   "language": "python",
   "name": "py38ml_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
